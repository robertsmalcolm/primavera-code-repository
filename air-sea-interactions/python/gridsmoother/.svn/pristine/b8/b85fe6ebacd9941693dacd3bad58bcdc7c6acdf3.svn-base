'''A module to allow the smoothing of iris cubes based on real space properties rather than grid indices '''

import iris
import numpy as np

__date__ = '$Date$ '
__rev__ = "$Rev$ "
__author__ = "$Author$ "
__HeadURL__ = "$HeadURL$ "
__id__ = "$Id$ "
__lastrev__ = "$LastChangedRevision$ "

__version__ = "0.1." + filter(str.isdigit, __rev__)


class GridSmoother(object):
    '''A class to hold mapping information needed to perform smoothing '''
    def __init__(self):
        '''Initialise smoother parameters'''
        self.lats = None
        self.lons = None
        self.shape = None
        self.mapping_data = {}
        self.metadata = {'version':__version__}

    def build(self, source_cube, fn_of_sep, fn_cutoff=1e-5, metadata=None, quiet=True):
        '''Build a structure for smoothing the data in a cube based on 
        spatial separation of grid points (in degrees) rather than on grid index
        
        Arguments:
        
        * source_cube:
            an iris Cube from which to take the latitude and longitude coordinates
        
        * fn_of_sep:
            a function returning a value when given the separation in degrees of a great circle
        
        Keywords:
        
        * fn_cutoff:
            minimum threshold for excluding points from mapping
        
        * metadata:
            dictionary of metadata to attach to the smoother
        
        
        Angular separation of pairs of points calculated using dot product of the two position vectors. 
        Expand position vectors in terms of latitude and longitude and assume all points are on Earth's surface 
        
        .. math::
            
            \\textbf{x} = R_E \\left[\cos(lat_x)\cos(lon_x), \cos(lat_x)\sin(lon_x) , \sin(lat_x)  \\right]
        
        Noting that :math:`\sin(90-lat) = \cos(lat)` and :math:`\cos(90-lat) = \sin(lat)`.
        
        The angle :math:`\\alpha` between two such vectors :math:`\\textbf{p}` and :math:`\\textbf{q}` is therefore
        
        .. math::

           \cos(\\alpha) &= \cos(lat_p)\cos(lat_q) \left[\cos(lon_p)\cos(lon_q) + \sin(lon_p)\sin(lon_p)\\right] + \sin(lat_p)sin(lat_q) \\\\
                         &= \\cos(lat_p)\cos(lat_q) \cos(\\Delta lon) + \sin(lat_p)\sin(lat_q)
           
        where :math:`\\Delta lon = lon_p - lon_q`.
        Smoothing coefficients are only computed and stored for a single longitude difference using the rotational symmetry of the model grid. 
        
        '''
        import itertools
        
        if not [coord.name() for coord in  source_cube.dim_coords] == ['latitude', 'longitude']:
            raise Exception('GridSmoother needs to build from a latitude-longitude cube, but found:\n' + str(source_cube))
        
        self.lats = source_cube.coord('latitude').points
        self.lons = source_cube.coord('longitude').points
        
        self.shape = source_cube.shape 
        
        if metadata is not None:
            if not isinstance(metadata, dict):
                raise Exception("metadata keyword must be a dictionary, received %s" % type(metadata))
            self.metadata.update(metadata)
            
        #for separation calculation need cos(lat), sin(lat) and cos(lon_1-lon_2)
        clat = np.cos(np.deg2rad(self.lats))
        slat = np.sin(np.deg2rad(self.lats))

        dlon = np.median(self.lons[1:] - self.lons[:-1])
        clon = np.cos(np.deg2rad(self.lons - dlon / 2))
        
        #iterate over each latitude calculating the angular separation of two points. 
        #Note that zonal symmetry means that data is not recomputed for each longitude
        nlat, nlon = self.shape
        temp_mapping_data = {i:[] for i in range(nlat)}
        old_i = -1
        for i, j, k in itertools.product(range(nlat), range(nlat), range(nlon)):
            if not quiet and old_i != i:
                print "Latitude %s of %s: %s" % (i, nlat, self.lats[i])
            if i == j and k == 0:                   #don't waste time computing separation of a point from itself
                ang_sep = 0.
            else:
                calpha = clat[i] * clat[j] * clon[-k] + slat[i] * slat[j]  # cosine of angle between vectors to each position
                ang_sep = np.rad2deg(np.arccos(calpha.clip(-1., 1.)))  # clip cosine to range [-1,1] to avoid numerical trouble
            point_weight = fn_of_sep(ang_sep)
            if point_weight >= fn_cutoff:
                temp_mapping_data[i].append((point_weight, (j, k)))
            old_i = i
        
        #normalise weights
        for i in range(nlat):
            sum_of_weights = sum([weight for weight, _ in temp_mapping_data[i]])
            tmp = {'weights':[], 'i_indices':[], 'j_indices':[]}
            
            for weight, point in temp_mapping_data[i]:
                tmp['weights'].append(weight)
                tmp['i_indices'].append(point[0])
                tmp['j_indices'].append(point[1])
                
            tmp['weights'] = np.array(tmp['weights']) / sum_of_weights
            tmp['i_indices'] = np.array(tmp['i_indices'])
            tmp['j_indices'] = np.array(tmp['j_indices'])
            self.mapping_data[i] = tmp
    
    def build_boxcar_lat_lon(self,source_cube, lat_width, lon_width, metadata=None, quiet=True ):
        '''
        Build a structure for box car smoothing the data in a cube.
        
        Arguments:
        
        * source_cube:
            an iris Cube from which to take the latitude and longitude coordinates
        
        * lat_width:
            full latitude width of the box car filter
        
        * lon_width:
            full longitude width of the box car filter
        
        Keywords:
        
        * fn_cutoff:
            minimum threshold for excluding points from mapping
        
        * metadata:
            dictionary of metadata to attach to the smoother
        
        
        Note: box car filters to not work close to the poles.
        
        '''
        
        
        import itertools
        
        if not [coord.name() for coord in  source_cube.dim_coords] == ['latitude', 'longitude']:
            raise Exception('GridSmoother needs to build from a latitude-longitude cube, but found:\n' + str(source_cube))
        
        self.lats = source_cube.coord('latitude').points
        self.lons = source_cube.coord('longitude').points
        
        self.shape = source_cube.shape 
        
        if metadata is not None:
            if not isinstance(metadata, dict):
                raise Exception("metadata keyword must be a dictionary, received %s" % type(metadata))
            self.metadata.update(metadata)
            
        #
        nlat, nlon = self.shape
        temp_mapping_data = []
        
        #cannot do anything where box will overlap the edge of the domain
        inds = np.where((self.lats + lat_width/2.0 < self.lats.max()) &
                        (self.lats - lat_width/2.0 > self.lats.min()))[0]
        operating_lat_range = (inds[0], inds[-1])
        
        #
        _lonsep = lambda lat1,lat2: np.abs(((lat1-lat2)-180.) %360. - 180.)
            
        i = operating_lat_range[0]
        for j,k in itertools.product(range(nlat), range(nlon)):
            lat_sep = np.abs(self.lats[i] - self.lats[j])
            lon_sep = _lonsep(0., self.lons[k])
            if lat_sep <= lat_width/2.0 and lon_sep <= lon_width/2:
                temp_mapping_data.append((1.0, (j,k)))
       
        weights = []
        i_indices = []
        j_indices = []
            
        for weight, point in temp_mapping_data:
            weights.append(weight)
            i_indices.append(point[0])
            j_indices.append(point[1])
        
        tmp = {}
        tmp['weights'] = np.array(weights) / sum(weights)
        tmp['j_indices'] = np.array(j_indices)  

        i_indices = np.array(i_indices)
         
        for i in range(nlat):
            tmp_i = tmp.copy()
            tmp_i['i_indices'] = i_indices + i - operating_lat_range[0]
            
            bad_i = list( set(tmp_i['i_indices']) - set(range(nlat)))
            
            if len(bad_i) != 0:
                bad_mask = [j in bad_i for j in tmp_i['i_indices']] #tmp_i['i_indices'] == bad_i
                new_i = np.ma.MaskedArray(tmp_i['i_indices'], bad_mask).compressed()
                new_j = np.ma.MaskedArray(tmp_i['j_indices'], bad_mask).compressed()
                new_w = np.ma.MaskedArray(tmp_i['weights'],   bad_mask).compressed()
                new_w /= new_w.sum()
                tmp_i = {'i_indices':new_i, 'j_indices':new_j, 'weights':new_w} 
            
            self.mapping_data[i] = tmp_i    
                    

    def smooth_3d_cube(self, cube, gridpoint_atol=1e-3):
        '''Smooth a 3D cube, e.g. time-lat-lon
        
        Arguments:
        
         * cube:
            Iris Cube to smooth.
        
        Keywords:
        
        * gridpoint_atol:
            absolute tolerance allowed in differences between latitude and 
            longitude coordinate point values.
            
        Returns a copy of the cube with smoothed data and additional attributes 
        copied from the GridSmoother metadata dictionary.
        '''
        smoothed_slices =iris.cube.CubeList()
        for cslice in cube.slices(['latitude','longitude']):
            smoothed_slices.append(self.smooth_2d_cube(cslice, gridpoint_atol))
        
        return smoothed_slices.merge_cube() #have to use merge here 
        
            
    def smooth_2d_cube(self, cube, gridpoint_atol=1e-3, quiet = True, reweight = False):
        '''Smooth a latitude-longitude cube
        
        Arguments:
        
        * cube:
            Must only have dimensions latitude-longitude
        
        Keywords:
        
        * gridpoint_atol:
            absolute tolerance allowed in differences between latitude and 
            longitude coordinate point values.
            
        * quiet:
            boolean for suppressing progress output (default = True)
        
        * reweight:
            set to True to re-weight the output (important for fields with 
            missing data which should not be included in the filter)
            
        Returns a copy of the cube with smoothed data and additional attributes 
        copied from the GridSmoother metadata dictionary.
        '''
        if not cube.shape == self.shape:
            msg = 'Supplied cube shape is not the same as the shape of the cube that this GridSmoother was built for'
            msg += "\n  GridSmoother.shape: %s\n  cube.shape: %s\n" % (self.shape, cube.shape)
            raise Exception(msg)
        
        for coord, values in [('latitude', self.lats), ('longitude', self.lons)]:
            if not np.allclose(cube.coord(coord).points, values, atol=gridpoint_atol):
                raise Exception('%s points in GridSmoother and cube do not match' % coord)
                
        outcube = cube.copy()
        outcube.data.fill(0.)
        outcube.attributes.update(self.metadata)
        weights_cube = outcube.copy()
        #lat_indices_to_mask = []
        
        for lat_index, _ in enumerate(self.lats):
            if not quiet:
                print lat_index+1," of ", len(self.lats), "\n" 
            map_data = self.mapping_data[lat_index]
            lon_indices = map_data['j_indices']
            lat_indices = map_data['i_indices']
            weights = map_data['weights']
            
            if len(weights) >0:
                for lon_index, _ in enumerate(self.lons):
                    lon_indices_temp = (lon_indices + lon_index) % self.shape[1]
                    #print cube.data[lat_index, lon_index]
                    if isinstance(cube.data, np.ma.masked_array) and cube.data.mask[lat_index, lon_index]:
                        continue
                    outcube.data[lat_indices, lon_indices_temp] += weights * cube.data[lat_index, lon_index]
                    weights_cube.data[lat_indices, lon_indices_temp] += weights
        
        if reweight:
            outcube.data /= weights_cube.data
        
        return outcube

    def save(self, filename):
        '''Save GridSmoother data to a file
        
        Arguments:
        
        * filename:
            filename to save to
        
        The output file is written as a gzipped json structure.            
        '''
        import json, gzip
        
        outdata = {'metadata':     self.metadata,
                   'latitudes':    self.lats.tolist(),
                   'longitudes':   self.lons.tolist(),
                   'shape':        self.shape,
                   'mapping_data': []}

        for i in range(self.shape[0]):
            
            outdata['mapping_data'].append({key:val.tolist() for key, val in self.mapping_data[i].items()}) 

        with gzip.open(filename, 'w') as filehandle:
            json.dump(outdata, filehandle, indent=2, sort_keys=True)

    
    def load(self, filename):
        '''Load data into GridSmoother
        
        Arguments:
        
        * filename:
            file to load from 
        
        '''
        import json, gzip
    
        with gzip.open(filename, 'r') as filehandle:
            gs_data = json.load(filehandle)

        self.metadata = gs_data['metadata']
        self.lats = np.array(gs_data['latitudes'])
        self.lons = np.array(gs_data['longitudes'])
        self.shape = tuple(gs_data['shape'])
        
        if len(self.lats) != self.shape[0]:
            raise Exception("shape[0] of source cube %s and length of latitudes array %s do not match" % (
                                                                                self.shape[0], len(self.lats)))
        if len(self.lons) != self.shape[1]:
            raise Exception("shape[1] of source cube %s and length of latitudes array %s do not match" % (
                                                                                self.shape[1], len(self.lons)))
        
        for k in ['weights', 'i_indices', 'j_indices']:
            for i, _ in enumerate(self.lats):#range(self.shape[0]):
                gs_data['mapping_data'][i][k] = np.array(gs_data['mapping_data'][i][k])
                
        self.mapping_data = gs_data['mapping_data']
        